evt_tax[evt_tax$data.source=="ACLED",1] = "A"
evt_tax[evt_tax$data.source=="SCAD",1] = "S"
evt_tax[evt_tax$data.source=="GED",1] = "G"
evt_tax[evt_tax$data.source=="GTD",1] = "GT"
# Adjust for ACLED
evt_tax$Base.Categories[3] = "Protests"
evt_tax$Base.Categories[5] = "Riots"
# Load actor taxonomy
act_tax = read.csv(paste0(path.to.tax,"actor_taxonomy.csv"),stringsAsFactors = F)
act_tax = read.csv(paste0(path.to.tax,"actor_taxonomy.csv"),stringsAsFactors = FALSE)
act_tax[act_tax$data.source=="acled",1] = "A"
act_tax[act_tax$data.source=="scad",1] = "S"
act_tax[act_tax$data.source=="ged",1] = "G"
act_tax[act_tax$data.source=="gtd",1] = "GT"
prec_tax = read.csv(paste0(path.to.tax,"precision_taxonomy.csv"),stringsAsFactors = FALSE)
prec_tax = prec_tax[,-3]
prec_tax[prec_tax$data.source=="ACLED",1] = "A"
prec_tax[prec_tax$data.source=="SCAD",1] = "S"
prec_tax[prec_tax$data.source=="GED",1] = "G"
prec_tax[prec_tax$data.source=="GTD",1] = "GT"
colnames(prec_tax)[2] = "base.categories"
prec_tax[1,]
# Only use the more rigorous categories when matching
evt_tax = evt_tax[,1:4] # Drop the most generic categories (3 and 4)
act_tax = act_tax[,1:3] # Drop the second level (which is tto generic)
# Assign Taxonomies as Lists
taxonomies = list(event_tax=evt_tax,actor_tax=act_tax,prec_tax=prec_tax)
output = meltt(S,A,G,GT,taxonomies = taxonomies,twindow = 1,spatwindow = 3,smartmatch=TRUE,certainty=NULL,partial=NULL,averaging=FALSE,weight=NA)
output = meltt(S,A,G,GT,taxonomies = taxonomies,twindow = 1,spatwindow = 3,smartmatch=TRUE,certainty=NA,partial=NA,averaging=FALSE,weight=NA)
output = meltt(S,A,G,GT,taxonomies = taxonomies,twindow = 1,spatwindow = 3)
output
# Support Functions --------------------------
review = function(data,minimal=T){ # Organize the data in workable format for review
set_names = c("A","S","G","GT")
# Snippets
snips = c("A-notes","S-issuenote","G-source_article","GT-summary")
# Dates
dates = paste0(set_names,"-date")
enddates = paste0(set_names,"-enddate")[c(2,3)] # ACLED and GTD are not episodal
# Locations
lat = paste0(set_names,"-latitude")
lon = paste0(set_names,"-longitude")
# Taxonomies
event = paste0(set_names,"-event_tax")
actor = paste0(set_names,"-actor_tax")
prec = paste0(set_names,"-prec_tax")
cnames = colnames(data)
if(minimal==T){
out = data[,c(dates,enddates,snips)]
}else{
out = data[,c(snips,dates,enddates,event,actor,prec,lat,lon)]
}
return(out)
}
review(output$recomposed.matches)
review = function(data,minimal=TRUE){ # Organize the data in workable format for review
set_names = c("A","S","G","GT")
# Snippets
snips = c("A-notes","S-issuenote","G-source_article","GT-summary")
# Dates
dates = paste0(set_names,"-date")
enddates = paste0(set_names,"-enddate")[c(2,3)] # ACLED and GTD are not episodal
# Locations
lat = paste0(set_names,"-latitude")
lon = paste0(set_names,"-longitude")
# Taxonomies
event = paste0(set_names,"-event_tax")
actor = paste0(set_names,"-actor_tax")
prec = paste0(set_names,"-prec_tax")
cnames = colnames(data)
if(minimal==TRUE){
out = data[,c(dates,enddates,snips)]
}else{
out = data[,c(snips,dates,enddates,event,actor,prec,lat,lon)]
}
return(out)
}
review(output$recomposed.matches)
nrow(output$recomposed.matches)
nrow(output$recomposed.matches)/904
review(output$recomposed.matches)
review = function(data,minimal=FALSE){ # Organize the data in workable format for review
set_names = c("A","S","G","GT")
# Snippets
snips = c("A-notes","S-issuenote","G-source_article","GT-summary")
# Dates
dates = paste0(set_names,"-date")
enddates = paste0(set_names,"-enddate")[c(2,3)] # ACLED and GTD are not episodal
# Locations
lat = paste0(set_names,"-latitude")
lon = paste0(set_names,"-longitude")
# Taxonomies
event = paste0(set_names,"-event_tax")
actor = paste0(set_names,"-actor_tax")
prec = paste0(set_names,"-prec_tax")
cnames = colnames(data)
if(minimal==TRUE){
out = data[,c(dates,enddates,snips)]
}else{
out = data[,c(snips,dates,enddates,event,actor,prec,lat,lon)]
}
return(out)
}
review(output$recomposed.matches)
write.csv(review(output$recomposed.matches,file="~/Desktop/nig11_melttout_715.csv")
write.csv(review(output$recomposed.matches))
write.csv(review(output$recomposed.matches),file="~/Desktop/nig11_melttout_715.csv")
write.csv(review(output$recomposed.matches),file="~/Desktop/nig11_melttout_715.csv",row.names = FALSE)
nrow(output$recomposed.matches)
5/nrow(output$recomposed.matches)
mm = review(output$recomposed.matches,minimal = TRUE)
mm
mm[1,]
mm[1,1:4]
mm[1,1:4*-1]
mm[,1:4*-1]
unclass(mm[,1:4*-1])
mm = mm[,1:4*-1]
mm
mm[,1]
mm = review(output$recomposed.matches,minimal = TRUE)
mm = mm[,(1:4)*-1]
mm[,1]
mm
mm[1,]
mm = mm[,(1:6)*-1]
mm = review(output$recomposed.matches,minimal = TRUE)
mm = mm[,(1:6)*-1]
mm[1,]
mm[,1]
mm[is.na(mm$`A-notes`),]
mm[!is.na(mm$`A-notes`),]
mm[!is.na(mm$`A-notes`),1]
mm[!is.na(mm[,1]),1]
tags = c()
for (i in 1:4){tags = rbind(tags,mm[!is.na(mm[,i]),1])}
tags
tags = c()
for (i in 1:4){t=mm[!is.na(mm[,i]);colnames(t)=NULL;tags = rbind(tags,,1])}
for (i in 1:4){t=mm[!is.na(mm[,i]); colnames(t)=NULL; tags = rbind(tags,,1])}
tags = c()
for (i in 1:4){t=mm[!is.na(mm[,i]); colnames(t)=NULL; tags = rbind(tags,,1])}
tags = c()
for (i in 1:4){t=mm[!is.na(mm[,i],); colnames(t)=NULL; tags = rbind(tags,,1])}
5+5;6+5
tags = c()
for (i in 1:4){t=mm[!is.na(mm[,i]),i]; colnames(t)=NULL; tags = rbind(tags,t)}
tags
dim(tags)
t=mm[!is.na(mm[,i]),i]
t
colnames(t)=NULL
head(t)
as.matrix(t)
tags = c()
for (i in 1:4){
t=mm[!is.na(mm[,i]),i]
colnames(t)=NULL
tags = rbind(tags,as.matrix(t))
}
tags
mm = review(output$recomposed.matches,minimal = TRUE)[,(1:6)*-1]
tags = c()
for (i in 1:4){
t=mm[!is.na(mm[,i]),i]
colnames(t)=NULL
tags = rbind(tags,as.matrix(t))
}
tags
rel.vars = c("date","latitude","longitude","event_tax","actor_tax","prec_tax")
rel.vars
rel.vars = c("date","A-notes","S-issuenote","G-source_article","GT-summary","latitude","longitude","event_tax","actor_tax","prec_tax")
snips = c("A-notes","S-issuenote","G-source_article","GT-summary")
sets = c("A","S","G","GT")
s = "A"
get(s)
sets
paste0(s,c("date","latitude","longitude","event_tax","actor_tax","prec_tax"))
paste(s,c("date","latitude","longitude","event_tax","actor_tax","prec_tax"),sep="-")
c(c("A-notes","S-issuenote","G-source_article","GT-summary")[s],
paste(sets[s],c("date","latitude","longitude","event_tax","actor_tax","prec_tax"),sep="-"))
sets = c("A","S","G","GT")
s=1
c(c("A-notes","S-issuenote","G-source_article","GT-summary")[s],
paste(sets[s],c("date","latitude","longitude","event_tax","actor_tax","prec_tax"),sep="-"))
t[,rel.vars]
rel.vars = c(c("A-notes","S-issuenote","G-source_article","GT-summary")[s],
paste(sets[s],c("date","latitude","longitude","event_tax","actor_tax","prec_tax"),sep="-"))
t[,rel.vars]
t
t = get(sets[s])
rel.vars = c(c("A-notes","S-issuenote","G-source_article","GT-summary")[s],
paste(sets[s],c("date","latitude","longitude","event_tax","actor_tax","prec_tax"),sep="-"))
t[,rel.vars]
t
t[,rel.vars]
rel.vars
rel.vars = c(c("notes","issuenote","source_article","summary")[s],
c("date","latitude","longitude","event_tax","actor_tax","prec_tax"))
rel.vars
t[,rel.vars]
colnames(t)[1] = "summary"
prox_events = c()
for ( s in 1:4){
t = get(c("A","S","G","GT")[s])
rel.vars = c(c("notes","issuenote","source_article","summary")[s],
c("date","latitude","longitude","event_tax","actor_tax","prec_tax"))
t = t[,rel.vars]
colnames(t)[1] = "summary"
prox_events = rbind(prox_events,t)
}
prox_events
head(prox_events = )
head(prox_events)
rel.vars = c("date",c("notes","issuenote","source_article","summary")[s],
c("latitude","longitude","event_tax","actor_tax","prec_tax"))
t = t[,rel.vars]
colnames(t)[2] = "summary"
prox_events = c()
for ( s in 1:4){
t = get(c("A","S","G","GT")[s])
t$data.source = c("A","S","G","GT")[s]
rel.vars = c("data.source","date",c("notes","issuenote","source_article","summary")[s],
c("latitude","longitude","event_tax","actor_tax","prec_tax"))
t = t[,rel.vars]
colnames(t)[2] = "summary"
prox_events = rbind(prox_events,t)
}
head(prox_events)
close2 = function(data,t.prox=1,d.prox=2){
require(geosphere)
counter <- 0
data$match <- 0
for(i in 1:nrow(data)){
cat(paste0("\n\n_",i,"_"))
if(i==1){next()}
dnow = data$date[i]
dlast = data$date[i-1]
tclose = (dnow - dlast) <= t.prox
km.now.to.last = distm(data[i,c("longitude","latitude")],data[c(i-1),c("longitude","latitude")])/1000
if(is.na(km.now.to.last)){next()}
sclose = km.now.to.last <= d.prox
if(sclose & tclose){
data$match[i-1] <- 1
data$match[i] <- 1
}
}
return(data)
}
close2(prox_events,t.prox = 1,d.prox = 3)
data = prox_events
require(geosphere)
counter <- 0
data$match <- 0
1:nrow(data)
cat(paste0("\n\n_",i,"_"))
i=1
i=2
rel.vars
head(prox_events)
prox_events = c()
for ( s in 1:4){
t = get(c("A","S","G","GT")[s])
t$data.source = c("A","S","G","GT")[s]
rel.vars = c("data.source","date",c("notes","issuenote","source_article","summary")[s],
c("latitude","longitude","event_tax","actor_tax","prec_tax"))
t = t[,rel.vars]
colnames(t)[3] = "summary"
prox_events = rbind(prox_events,t)
}
prox_events$date
class(prox_events$date)
order(prox_events$date)
prox_events[order(prox_events$date),]
prox_events = prox_events[order(prox_events$date),]
close2(prox_events,t.prox = 1,d.prox = 3)
close = function(data,t.prox=1,d.prox=2){
require(geosphere)
counter <- 0
data$match <- 0
for(i in 1:nrow(data)){
cat(paste0("\n\n_",i,"_"))
if(i==1){next()}
dnow = data$date[i]
dlast = data$date[i-1]
tclose = (dnow - dlast) <= t.prox
km.now.to.last = distm(data[i,c("longitude","latitude")],data[c(i-1),c("longitude","latitude")])/1000
if(is.na(km.now.to.last)){next()}
sclose = km.now.to.last <= d.prox
if(sclose & tclose){
data$match[i-1] <- 1
data$match[i] <- 1
}
}
return(data)
}
clean_events = c()
for ( s in 1:4){
t = get(c("A","S","G","GT")[s])
t$data.source = c("A","S","G","GT")[s]
rel.vars = c("data.source","date",c("notes","issuenote","source_article","summary")[s],
c("latitude","longitude","event_tax","actor_tax","prec_tax"))
t = t[,rel.vars]
colnames(t)[3] = "summary"
clean_events = rbind(clean_events,t)
}
clean_events = clean_events[order(clean_events$date),] # Order entries
prox_events = close(clean_events,t.prox = 1,d.prox = 3)
head(prox_events)
head(prox_events[prox_events$match==1,])
prox_events = prox_events[prox_events$match==1,]
prox_events
prox_events$summary %in% tags
!prox_events$summary %in% tags
prox_events[!prox_events$summary %in% tags,]
prox_events = prox_events[!prox_events$summary %in% tags,]
row.names(prox_events) = 1:nrow(prox_events)
prox_events
dates = unique(prox_events$date)
dates
day
day = 1
prox_events$date==dates[day]
sub = prox_events[prox_events$date==dates[day],]
sub
unique(sub$data.source)==1
unique(sub$data.source)
length(unique(sub$data.source))==1
prox_events[prox_events$date==dates[day],"data.source"]
sub = prox_events[prox_events$date==dates[day],]
prox_events$redun = 0
dates = unique(prox_events$date)
prox_events$redun = 0
for (day in 1:length(dates)){
if (length(unique(prox_events[prox_events$date==dates[day],"data.source"]))==1){
prox_events[prox_events$date==dates[day],"redun"] = 1
}
}
prox_events[prox_events$redun==1,]
length(unique(prox_events[prox_events$date==dates[day],"data.source"]))==1
prox_events[prox_events$redun==1,] %>% head(.)
prox_events[prox_events$redun==0,] %>% head(.)
prox_events_cl = prox_events[prox_events$redun==0,]
prox_events_cl
dates = unique(prox_events$date)
prox_events$redun = 0
for (day in 1:length(dates)){
if (length(unique(prox_events[prox_events$date==dates[day],"data.source"]))==1){
prox_events[prox_events$date==dates[day],"redun"] = 1
}
}
prox_events_cl = prox_events[prox_events$redun==0,]
prox_events_cl
clean_events = c()
for ( s in 1:4){
t = get(c("A","S","G","GT")[s])
t$data.source = c("A","S","G","GT")[s]
rel.vars = c("data.source","date",c("notes","issuenote","source_article","summary")[s],
c("latitude","longitude","event_tax","actor_tax","prec_tax"))
t = t[,rel.vars]
colnames(t)[3] = "summary"
clean_events = rbind(clean_events,t)
}
clean_events = clean_events[order(clean_events$date),] # Order entries
# LOCATE proximate entries
prox_events = close(clean_events,t.prox = 1,d.prox = 3)
prox_events = prox_events[prox_events$match==1,] # Only "matches"
# REMOVE Meltt located events
prox_events = prox_events[!prox_events$summary %in% tags,]
# CLEAN of days that are only picking up occurrence within the same DF
dates = unique(prox_events$date)
prox_events$redun = 0
for (day in 1:length(dates)){
if (length(unique(prox_events[prox_events$date==dates[day],"data.source"]))==1){
prox_events[prox_events$date==dates[day],"redun"] = 1
}
}
prox_events_cl = prox_events[prox_events$redun==0,]
row.names(prox_events_cl) = 1:nrow(prox_events_cl)
prox_events_cl
prox_events_cl[,1:2]
write.csv(prox_events_cl,paste0(path.to.wd,"nig11_falseNeg_715.csv"))
write.csv(prox_events_cl,paste0(path.to.wd,"nig11_falseNeg_715.csv"),row.names = F)
write.csv(prox_events_cl,paste0(path.to.wd,"nig11_falseNeg_715.csv"),row.names = FALSE)
day
dates[day]
class(dates[day])
dates[day]-1
dates[day]+1
sub = prox_events[prox_events$date==dates[day],]
sub_m = prox_events[prox_events$date==dates[day],"data.source"]
sub_m
sub_min = prox_events[prox_events$date==dates[day]-1,"data.source"]
sub_min
dates[day]-1
sub_min = prox_events[prox_events$date==(dates[day]-1),"data.source"]
sub_min
sub_max = prox_events[prox_events$date==dates[day]+1,"data.source"]
sub_max
sub = c(sub_min,sub_m,sub_max)
sub
dates = unique(prox_events$date)
prox_events$redun = 0
for (day in 1:length(dates)){
sub_min = prox_events[prox_events$date==(dates[day]-1),"data.source"]
sub_m = prox_events[prox_events$date==dates[day],"data.source"]
sub_max = prox_events[prox_events$date==dates[day]+1,"data.source"]
sub = c(sub_min,sub_m,sub_max)
if (length(unique(sub))==1){
prox_events[prox_events$date==dates[day],"redun"] = 1
}
}
prox_events_cl = prox_events[prox_events$redun==0,]
row.names(prox_events_cl) = 1:nrow(prox_events_cl)
prox_events_cl
prox_events_cl[,1:2] # Check
write.csv(prox_events_cl,paste0(path.to.wd,"nig11_falseNeg_715.csv"),row.names = FALSE)
mm = review(output$recomposed.matches,minimal = TRUE)[,(1:6)*-1]
tags = c()
for (i in 1:4){
t=mm[!is.na(mm[,i]),i]
colnames(t)=NULL
tags = rbind(tags,as.matrix(t))
}
# CLEAN original data (to ease review)
clean_events = c()
for ( s in 1:4){
t = get(c("A","S","G","GT")[s])
t$data.source = c("A","S","G","GT")[s]
rel.vars = c("data.source","date",c("notes","issuenote","source_article","summary")[s],
c("latitude","longitude","event_tax","actor_tax","prec_tax"))
t = t[,rel.vars]
colnames(t)[3] = "summary"
clean_events = rbind(clean_events,t)
}
clean_events = clean_events[order(clean_events$date),] # Order entries
prox_events = close(clean_events,t.prox = 1,d.prox = 3)
prox_events = prox_events[prox_events$match==1,] # Only "matches"
# REMOVE Meltt located events
prox_events = prox_events[!prox_events$summary %in% tags,]
# CLEAN of days that are only picking up occurrence within the same DF
dates = unique(prox_events$date)
prox_events$redun = 0
for (day in 1:length(dates)){
sub_min = prox_events[prox_events$date==(dates[day]-1),"data.source"]
sub_m = prox_events[prox_events$date==dates[day],"data.source"]
sub_max = prox_events[prox_events$date==dates[day]+1,"data.source"]
sub = c(sub_min,sub_m,sub_max)
if (length(unique(sub))==1){
prox_events[prox_events$date==dates[day],"redun"] = 1
}
}
prox_events_cl = prox_events[prox_events$redun==0,]
row.names(prox_events_cl) = 1:nrow(prox_events_cl)
prox_events_cl[,1:2] # Check
meltt_events = prox_events[prox_events$summary %in% tags,]
dim(meltt_events)
prox_events_main = close(clean_events,t.prox = 1,d.prox = 3)
prox_events_main = prox_events_main[prox_events_main$match==1,] # Only "matches"
prox_events = prox_events_main[!prox_events_main$summary %in% tags,]
meltt_events = prox_events_main[prox_events_main$summary %in% tags,]
dim(meltt_events)
dates = unique(prox_events$date)
prox_events$redun = 0
for (day in 1:length(dates)){
sub_min = prox_events[prox_events$date==(dates[day]-1),"data.source"]
sub_m = prox_events[prox_events$date==dates[day],"data.source"]
sub_max = prox_events[prox_events$date==dates[day]+1,"data.source"]
sub = c(sub_min,sub_m,sub_max)
if (length(unique(sub))==1){
prox_events[prox_events$date==dates[day],"redun"] = 1
}
}
prox_events_cl = prox_events[prox_events$redun==0,]
row.names(prox_events_cl) = 1:nrow(prox_events_cl)
prox_events_cl[,1:2] # Check
prox_events_cl$meltt_identified = 0
meltt_events$meltt_identified = 1
out = rbind(prox_events_cl,meltt_events)
colnames(prox_events_cl)
prox_events_cl = prox_events_cl[,(9:10)*-1] # Check
prox_events = prox_events_main[!prox_events_main$summary %in% tags,]
meltt_events = prox_events_main[prox_events_main$summary %in% tags,]
# CLEAN of days that are only picking up occurrence within the same DF
dates = unique(prox_events$date)
prox_events$redun = 0
for (day in 1:length(dates)){
sub_min = prox_events[prox_events$date==(dates[day]-1),"data.source"]
sub_m = prox_events[prox_events$date==dates[day],"data.source"]
sub_max = prox_events[prox_events$date==dates[day]+1,"data.source"]
sub = c(sub_min,sub_m,sub_max)
if (length(unique(sub))==1){
prox_events[prox_events$date==dates[day],"redun"] = 1
}
}
prox_events_cl = prox_events[prox_events$redun==0,]
row.names(prox_events_cl) = 1:nrow(prox_events_cl)
prox_events_cl = prox_events_cl[,(9:10)*-1] # Check
colnames(prox_events_cl)
prox_events_cl$meltt_identified = 0
meltt_events$meltt_identified = 1
out = rbind(prox_events_cl,meltt_events)
names(meltt_events)
out = rbind(prox_events_cl,meltt_events[,-9])
out
write.csv(out,paste0(path.to.wd,"nig11_falseNeg_715.csv"),row.names = FALSE)
data(crashMD)
output <- meltt(crash_data1,crash_data2,crash_data3,
taxonomies = crash_taxonomies,twindow = 1,spatwindow = 3)
summary(output)
install.packages("~/Dropbox/INSPIRE project/Iterative Procedure/meltt package/meltt_0.2.3.tar.gz", repos = NULL, type = "source")
install.packages("~/Dropbox/INSPIRE project/Iterative Procedure/meltt package/meltt_0.2.5.tar.gz", repos = NULL, type = "source")
